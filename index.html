<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chiyu Ma</title>
  
  <meta name="author" content="Chiyu Ma">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Chiyu Ma - Ph.D. candidate at Dartmouth specializing in Large Scale LLM post-training, Reinforcement Learning and Supervised Fintuning.">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/dartmouth_logo.jpeg" type="image/x-icon"/>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chiyu Ma</name>
              </p>
<p>
  I am Chiyu (Henry) Ma, a third-year Computer Science Ph.D. student at 
  <a href="https://home.dartmouth.edu/">Dartmouth ðŸŒ²</a>, 
  advised by <a href="https://www.cs.dartmouth.edu/~soroush/">ðŸŒŸ Prof. Soroush Vosoughi</a>. 
  Currently, I am also a Research Intern at Qwen Pilot, where I am focusing on research in large-scale post-training of Large Language Models (LLMs).
</p>
<p>
  Previously, I earned my M.S. in Statistical Science from Duke University. As a member of the Interpretable Machine Learning Lab, I was advised by 
  <a href="https://users.cs.duke.edu/~cynthia/">ðŸŒŸ Prof. Cynthia Rudin</a> 
  and collaborated with 
  <a href="https://mcec.umaine.edu/home/faculty222/chen-chaofan/">ðŸŒŸ Prof. Chaofan Chen</a> (UMaine). 
  I hold a B.S. in Statistics with Honors (Computational Finance concentration) from Carnegie Mellon University, where I conducted research on statistical analysis in biological applications with 
  <a href="https://sites.google.com/site/zjbranson/">ðŸŒŸ Prof. Zach Branson</a>.
</p>
              <p style="text-align:center">
                <a href="mailto:Chiyu.ma.gr@dartmouth.edu"><i class="fa fa-envelope" style="font-size:21px"></i></a> &nbsp/&nbsp
                <a href="https://https://github.com/Henrymachiyu"><i class="fa fa-github" style="font-size:23px"></i></a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/henry-chiyu-ma-3b7b30203/"><i class="fa fa-linkedin" style="font-size:22px"></i></a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=h_3TRv0AAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:26%;max-width:26%">
              <a href="images/152928.jpg
"><img style="width:70%;max-width:70%" alt="profile photo" src="images/152928.jpg
" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
          <hr style="border:0; height:1px; background-image:linear-gradient(to right, transparent, #ddd, transparent);">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">

              <heading>Research</heading>
<p>
My prior research centered on <b>Interpretability in Computer Vision Models (CNNs and ViTs)</b> 
  and ensuring the reliability of <b>LLM-as-a-Judge frameworks</b>. 
  Building on this foundation, I have pivoted to <b>Large-scale Post-training</b>, 
  where I design algorithms specifically aimed at eliciting and enhancing the complex reasoning capabilities of LLMs.            </td>
          </tr>
        </tbody></table>
<hr style="border:0; height:1px; background-image:linear-gradient(to right, transparent, #ddd, transparent);">



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">

                <heading>News</heading>
<p>
  <span style="font-style: italic;">[Jan. 28, 2026]</span> Two papers accepted to ICLR 2026. Thanks to my excellent collaborators. See you in Rio!
<br>
<p>
  <span style="font-style: italic;">[Sept. 2025]</span> Two papers accepted to EMNLP 2025 and One paper accepted to NeurIPS 2025. See you in Suzhou and SD!
<br>
<p>
  <span style="font-style: italic;">[Jun. 2025]</span> Started as a research intern at Tongyi Lab Qwen Pilot Team, Hangzhou, CA</a>. Excited to meet friends in Hangzhou!
<br>	

            </td>
          </tr>
        </tbody></table>

<hr style="border:0; height:1px; background-image:linear-gradient(to right, transparent, #ddd, transparent);">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">

              <heading>Selected Publications</heading>
              <p style="font-size:95%;">
            	Some interesting papers about my work and research on LLM Post-training and Reinforcement Learning.
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fdnas_image'><video  width=100% height=100% muted autoplay loop>
                Your browser does not support the video tag.
                </video></div>
                <img src='images/logp.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://openreview.net/forum?id=r6Pw3RiMYL">
                <papertitle> On the Direction of RLVR Updates for LLM Reasoning: Identification and Exploitation </papertitle>
              </a>
              <br>
              Kexin Huang, Haoming Meng, Junkang Wu, Jinda Lu, <b>Chiyu Ma</b>, Ziqian Chen, Xue Wang, Bolin Ding, Jiancan Wu, Xiang Wang, Xiangnan He, Guoyin Wang, Jingren Zhou
              <br>
                <em>ICLR 2026</em>
              <br>
                <a href="https://openreview.net/forum?id=r6Pw3RiMYL">Paper</a>
              <br>
              <p style="font-size:90%; margin-top:8px; color:#555;">
                This paper proposes that log-probability difference is a more promising metric than entropy for evaluating how LLMs evolve during training, a claim supported by both empirical and theoretical analysis.
              </p>
            </td>
          </tr>
		  
			<tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fdnas_image'><video  width=100% height=100% muted autoplay loop>
                Your browser does not support the video tag.
                </video></div>
                <img src='images/sparse.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://openreview.net/forum?id=r6Pw3RiMYL">
                <papertitle> Sparse but Critical: A Token-Level Analysis of Distributional Shifts in RLVR Fine-Tuning of LLMs </papertitle>
              </a>
              <br>
              Haoming Meng, Kexin Huang, Shaohang Wei, <b>Chiyu Ma</b>, Shuo Yang, Xue Wang, Guoyin Wang, Bolin Ding, Jingren Zhou 
              <br>
                <em>ICLR 2026</em>
              <br>
                <a href="https://openreview.net/forum?id=8vWIXno8LW">Paper</a>
              <br>
              <p style="font-size:90%; margin-top:8px; color:#555;">
                This paper  sheds light on the distributional changes induced by RLVR and provides a granular, token-level lens for understanding and improving RL fine-tuning in LLMs.
              </p>
            </td>
          </tr>
			
<tr>
      <td colspan="2" style="padding:40px 20px 10px 20px; width:100%; vertical-align:middle">
        <p style="font-size:95%;">
          My other works on the Reliability of LLM-as-Judge.
        </p>
      </td>
    </tr>

    <tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='fdnas_image'>
            <video width=100% height=100% muted autoplay loop>
              Your browser does not support the video tag.
            </video>
          </div>
          <img src='images/judemm.png' width="160"> 
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="#">
          <papertitle>Judging with Many Minds: Do More Perspectives Mean Less Prejudice? On Bias Amplifications and Resistance in Multi-Agent Based LLM-as-Judge </papertitle>
        </a>
        <br>
        <b>Chiyu Ma* </b>, Enpei Zhang*, Yilun Zhao, Wenjun Liu, Yaning Jia, Peijun Qing, Lin Shi, Arman Cohan, Yujun Yan, Soroush Vosoughi
        <br>
        <em> Findings of EMNLP 2025 </em> 
        <br>
        <a href="#">Paper</a>
        <br>
        <p style="font-size:90%; margin-top:8px; color:#555;">
           This paper provides counter-intuitive findings that multi-agent based LLM-as-Judges do not always provide reliable answers as people previously thought. We explored the phenomenon of bias amplifications in both Multi-agent Debate and LLm-as-Meta-Judge settings. 
        </p>
      </td>
    </tr>

	    <tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='fdnas_image'>
            <video width=100% height=100% muted autoplay loop>
              Your browser does not support the video tag.
            </video>
          </div>
          <img src='images/jj.png' width="160"> 
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="#">
          <papertitle>Judging the judges: A systematic study of position bias in llm-as-a-judge </papertitle>
        </a>
        <br>
        Lin Shi, <b>Chiyu Ma </b>, Wenhua Liang, Xingjian Diao, Weicheng Ma, Soroush Vosoughi
        <br>
        <em> Orals of AACL 2025 </em> 
        <br>
        <a href="#">Paper</a>
        <br>
        <p style="font-size:90%; margin-top:8px; color:#555;">
           This paper provides a thorough analysis on how position bias spread over pair-wise and list-wise comparisons in the state-of-the-arts LLMs such as Gemini, GPT, and Claude.  
        </p>
      </td>
    </tr>
	
      <td colspan="2" style="padding:40px 20px 10px 20px; width:100%; vertical-align:middle">
        <p style="font-size:95%;">
          My earlier works on Interpretability. Although I no longer work in this area, these projects represent a cherished part of my research journey.
        </p>
      </td>
    </tr>
			
	<tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='fdnas_image'>
            <video width=100% height=100% muted autoplay loop>
              Your browser does not support the video tag.
            </video>
          </div>
          <img src='images/protopair.png' width="160"> 
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="#">
          <papertitle> ProtoPairNet: Interpretable Regression through Prototypical Pair Reasoning </papertitle>
        </a>
        <br>
        Rose Gurung, Ronilo Ragodos,<b>Chiyu Ma </b>, Tong Wang, Chaofan Chen
        <br>
        <em> NeurIPs 2025 </em> 
        <br>
        <a href="#">Paper</a>
        <br>
        <p style="font-size:90%; margin-top:8px; color:#555;">
           This paper propopses an interpretable alorightms with prototypical pairs for tasks with continuous labels. This algorithm is further evaluated in Reward Prediction (RL settings) and Age predictions (Classical Regression tasks). 
        </p>
      </td>
    </tr>

	<tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='fdnas_image'>
            <video width=100% height=100% muted autoplay loop>
              Your browser does not support the video tag.
            </video>
          </div>
          <img src='images/protovit.png' width="160"> 
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="#">
          <papertitle> Interpretable Image Classification with Adaptive Prototype-based Vision Transformers </papertitle>
        </a>
        <br>
        <b>Chiyu Ma </b>, Jon Donnelly, Wenjun Liu, Soroush Vosoughi, Cynthia Rudin, Chaofan Chen
        <br>
        <em> NeurIPs 2024 </em> 
        <br>
        <a href="#">Paper</a>
        <br>
        <p style="font-size:90%; margin-top:8px; color:#555;">
           This paper propopses an interpretable alorightms on ViTs with Prototical Parts. By greedying matching algorithms, we decomposes the prototypical parts into small patches that can freely learn features to represent a more local feature. 
        </p>
      </td>
    </tr>

		<tr onmouseout="CMI_stop()" onmouseover="sgcl_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='fdnas_image'>
            <video width=100% height=100% muted autoplay loop>
              Your browser does not support the video tag.
            </video>
          </div>
          <img src='images/protoconcept.png' width="160"> 
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="#">
          <papertitle> Interpretable Image Classification with Adaptive Prototype-based Vision Transformers </papertitle>
        </a>
        <br>
        <b>Chiyu Ma* </b>, Brandon Zhao *, Chaofan Chen, Cynthia Rudin
        <br>
        <em> NeurIPs 2023 </em> 
        <br>
        <a href="#">Paper</a>
        <br>
        <p style="font-size:90%; margin-top:8px; color:#555;">
           This paper propopses an interpretable alorightms on CNNs that provides geometrically equivalent visualizations of prototypical concepts. This is the first work in prototyped based methods that extract concepts from training set. 
        </p>
      </td>
    </tr>
			
	

			
        </tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Academic Service</heading>
        <p style="font-size:95%;">
          <strong>Conference Reviewer:</strong> <br>
          ICLR (2025, 2026), ICML (2024â€“2026), NeurIPS (2024, 2025), AAAI (AISI Track 2023)
          <br><br>
          <strong>Workshop Reviewer:</strong> <br>
          NeurIPS IAI Workshop (2024), ICLR LLM Reasoning and Planning Workshop (2025)
          <br><br>
          <strong>Journal Reviewer:</strong> <br>
          Transactions on Machine Learning Research (TMLR)
        </p>
      </td>
    </tr>
  </tbody>
</table>

<hr style="border:0; height:1px; background-image:linear-gradient(to right, transparent, #ddd, transparent);">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Fun Stuff</heading>
              <p>
                Racingâ€”a happy part of my life. I particularly enjoy go-karting and circuit racing (some fun facts:
                  <a href="https://www.instagram.com/p/Ce-IBtFsBUl/">1st</a> and <a href="https://www.instagram.com/p/CgV3251sPcJ/">2nd</a> place at Supercharged). But there is one type of racing that I have yet to tryâ€”my favorite rally driving (My favorite rally driver is Han Han).
              </p>
            </td>
          </tr>
        </tbody></table>

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=IMj5QOauaOh3itXiv54K4YbC6WTpio8QQs1f5DGrnzo&cl=ffffff&w=120&h=80"></script>
<div style="height:1px; margin-top:20px; margin-bottom:20px; background-image:linear-gradient(to right, transparent, #ddd, transparent);"></div>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">this cool guy</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
